# Gemini settings
GEMINI_API_KEY=your-gemini-api-key
GEMINI_MODEL_ID=gemini-2.5-pro-preview-06-05
MODEL_CYPHER_ID=gemini-2.5-flash-lite-preview-06-17

# Local model settings
# Example for Ollama:
LOCAL_MODEL_ENDPOINT="http://localhost:11434/v1"
# 本地电脑
LOCAL_ORCHESTRATOR_MODEL_ID="qwen3:0.6b"
LOCAL_CYPHER_MODEL_ID="qwen3:0.6b"
LOCAL_CODE_EMBEDDING_MODEL_ID="jina-embeddings-v3"
LOCAL_TEXT_EMBEDDING_MODEL_ID="Qwen3-Embeddings-0.6B"
# 服务器
#LOCAL_ORCHESTRATOR_MODEL_ID="llama3.3:70b"
#LOCAL_CYPHER_MODEL_ID="llama3.3:70b"
LOCAL_EMBEDDING_MODEL_ID="embeddinggemma"
LOCAL_MODEL_API_KEY="ollama" # Ollama uses "ollama" as a placeholder

MEMGRAPH_HOST=localhost
MEMGRAPH_PORT=7687
MEMGRAPH_HTTP_PORT=7444
LAB_PORT=3000
#TARGET_REPO_PATH=/data/sanglei/CodeGraphRAG/test-project/test1/kafka
#ANTIPATTERN_RELATION_PATH=/data/sanglei/CodeGraphRAG/test-project/test1/20
TARGET_REPO_PATH=D:\\Disaster\\Codefield\\Code_Python\\CodeGraphRAG\\test-project\\kafka
ANTIPATTERN_RELATION_PATH=D:\\Disaster\\Codefield\\Code_Python\\CodeGraphRAG\\test-project\\test1\\20
HF_MODELS_HOME=D:\\Disaster\\Codefield\\Code_Python\\CodeGraphRAG\\codebase_rag\\services\\embedding